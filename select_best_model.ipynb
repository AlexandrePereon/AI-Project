{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libs\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Load the data\n",
    "filename = './AI_Project_Data/cleaned_data.csv'\n",
    "employee_data = pd.read_csv(filename)\n",
    "\n",
    "# Displaying data.head() to see the first 5 rows of the data\n",
    "employee_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Attrition values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = employee_data.copy()\n",
    "\n",
    "y = employee_df[\"Attrition\"]\n",
    "X = employee_df.drop(columns=[\"Attrition\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # TODO : shuffle ? cross validation\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"SVC\": SVC(probability=True, random_state=42),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"NaiveBayes\": GaussianNB(),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42), \n",
    "    \"Perceptron\": Perceptron(random_state=42),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions[model_name] = model.predict(X_test)    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "        plt.plot(recall, precision, label=f\"{model_name}\")\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title(f\"{name} Matrice de Confusion :\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8)) \n",
    "for name, model in models.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "scores = []\n",
    "for name, y_pred in predictions.items():\n",
    "    scores.append({\n",
    "        'Model': name,\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "    })\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "print(scores_df)\n",
    "print('_'*50)\n",
    "print('Sorted Dataframe')\n",
    "print('_'*50)\n",
    "scores_df = scores_df.sort_values(['F1 Score', 'Precision', 'Accuracy', 'Recall'], ascending=False) # TODO : change order\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full params grids : \n",
    "\n",
    "svc_params_grid = {\n",
    "    # general parameters\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'decision_function_shape': ['ovo', 'ovr'],\n",
    "    'random_state': [42],\n",
    "    'shrinking': [True, False],\n",
    "    'probability': [True],\n",
    "    'cache_size': [200, 500, 1000],\n",
    "    'verbose': [False],\n",
    "    \n",
    "    # specific parameters for the 'rbf' and 'sigmoid' kernels\n",
    "    'gamma': ['scale', 'auto', 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \n",
    "    # Specific polyinomial kernel parameters\n",
    "    'degree': [2, 3, 4, 5],\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0],\n",
    "    \n",
    "    # tolerance and maximum number of iterations\n",
    "    'tol': [1e-5, 1e-4, 1e-3],\n",
    "    'max_iter': [-1, 1000, 2000, 5000]\n",
    "}\n",
    "\n",
    "\n",
    "rf_params_grid = {\n",
    "    # Paramètres de la forêt\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'oob_score': [True, False],\n",
    "    \n",
    "    # Paramètres des arbres individuels\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_leaf_nodes': [None, 50, 100, 200],\n",
    "    \n",
    "    # Paramètres de randomisation\n",
    "    'random_state': [42],\n",
    "    \n",
    "    # Paramètres pour données déséquilibrées\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    \n",
    "    # Paramètres de parallélisation\n",
    "    'n_jobs': [-1],\n",
    "    \n",
    "    # Paramètres de critère de split\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    \n",
    "    # Paramètres de régularisation\n",
    "    'max_samples': [0.5, 0.7, 0.9, None],\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Définition d'une grille simplifiée de paramètres\n",
    "rf_params_grid = {\n",
    "    # Paramètres essentiels\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    \n",
    "    # Paramètres de base\n",
    "    'random_state': [42],\n",
    "    'n_jobs': [-1],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "# Configuration du GridSearchCV avec des options avancées\n",
    "RandomForest_model = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=rf_params_grid,\n",
    "    cv=5,  # Validation croisée à 5 plis\n",
    "    n_jobs=-1,  # Utilise tous les cœurs disponibles\n",
    "    scoring=['accuracy', 'f1', 'precision', 'recall', 'roc_auc'],\n",
    "    refit='accuracy',  # Réentraîne sur la meilleure métrique accuracy\n",
    "    verbose=2,\n",
    "    return_train_score=True,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "# model fitting\n",
    "RandomForest_model.fit(X_train, y_train)\n",
    "\n",
    "# getting best parameters\n",
    "best_rf_model = RandomForest_model.best_estimator_\n",
    "\n",
    "# displaying results\n",
    "print(\"\\nMeilleurs paramètres trouvés :\")\n",
    "print(f\"\\nRandomForest {RandomForest_model.best_params_}\")\n",
    "print(\"\\nMeilleur score de validation croisée:\")\n",
    "print(f\"\\nRandomForest {RandomForest_model.best_score_}\")\n",
    "\n",
    "\n",
    "# displaying scores for metrics\n",
    "rf_results = pd.DataFrame(RandomForest_model.cv_results_)\n",
    "print(\"\\nRésultats détaillés pour la meilleure configuration:\")\n",
    "metrics = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\n",
    "for metric in metrics:\n",
    "    mean_score = rf_results[f'mean_test_{metric}'].iloc[rf_results['rank_test_accuracy'].argmin()]\n",
    "    std_score = rf_results[f'std_test_{metric}'].iloc[rf_results['rank_test_accuracy'].argmin()]\n",
    "    print(f\"RandomForest - {metric}: {mean_score:.3f} (+/- {std_score*2:.3f})\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
